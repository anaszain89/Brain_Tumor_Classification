{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "from PIL import Image\n",
    "\n",
    "#importing specific functions\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-define functions\n",
    "def cv_optimize(clf, parameters, X, y, n_jobs=1, n_folds=5, score_func=None):\n",
    "    if score_func:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, n_jobs=n_jobs, scoring=score_func)\n",
    "    else:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, n_jobs=n_jobs, cv=n_folds)\n",
    "    gs.fit(X, y)\n",
    "    #print(\"BEST\", gs.best_params_, gs.best_score_, gs.grid_scores_)\n",
    "    best = gs.best_estimator_\n",
    "    return best\n",
    "\n",
    "def do_classify_aa(clf, parameters, indf, featurenames, targetname, target1val, score_func=None, n_folds=5, n_jobs=1):\n",
    "    subdf=indf[featurenames]\n",
    "    X=subdf.values\n",
    "    X=scale(X)\n",
    "    y=(indf[targetname].values==target1val)*1\n",
    "    training_accuracy = np.zeros(10)\n",
    "    test_accuracy=np.zeros(10)\n",
    "    test_auc=np.zeros(10)\n",
    "    \n",
    "    for idx,train_test in enumerate(skf.split(X,y)):\n",
    "        X_train, X_test = X[train_test[0]], X[train_test[1]]\n",
    "        y_train, y_test = y[train_test[0]], y[train_test[1]]\n",
    "        \n",
    "        if parameters:\n",
    "            clf = cv_optimize(clf, parameters, X_train, y_train, n_jobs=n_jobs, n_folds=n_folds, score_func=score_func)\n",
    "        clf=clf.fit(X_train, y_train)\n",
    "        pred = clf.predict(X_test)\n",
    "        probs = clf.predict_proba(X_test)\n",
    "        training_accuracy[idx] = clf.score(X_train, y_train)\n",
    "        test_accuracy[idx] = accuracy_score(y_test, pred)\n",
    "        test_auc[idx] = roc_auc_score(y_test, probs[:,1])\n",
    "        #print(idx)\n",
    "    print(\"############# based on k-fold cross-validation predictions ################\")\n",
    "    print(\"Training Accuracy %0.2f +/- %0.3f\" % (training_accuracy.mean(), training_accuracy.std()))\n",
    "    #print(\")\n",
    "    print(\"***** Target : GBM vs METS\")\n",
    "    print(clf)\n",
    "    print(\"Accuracy on test data:     %0.2f +/- %0.3f\" % (test_accuracy.mean(), test_accuracy.std()))\n",
    "    print(\"AUC on test data:     %0.2f +/- %0.3f\" % (test_auc.mean(), test_auc.std()))\n",
    "\n",
    "    #print(confusion_matrix(y, pred))\n",
    "    print(\"########################################################\")\n",
    "    return clf, test_accuracy, test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the pre-extracted features\n",
    "dfglioma=pd.read_csv(\"../data/glioma_all_featarray.csv\")\n",
    "dfglioma.head()\n",
    "colswewant_cont = list(dfglioma)\n",
    "colswewant_cont.pop()\n",
    "Targets=['Targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation methods\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, random_state=2652124)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#tts = train_test_split(n_splits=10, random_state=2652124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# based on k-fold cross-validation predictions ################\n",
      "Training Accuracy 1.00 +/- 0.000\n",
      "***** Target : GBM vs METS\n",
      "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Accuracy on test data:     0.71 +/- 0.132\n",
      "AUC on test data:     0.85 +/- 0.161\n",
      "########################################################\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clfsvc = svm.SVC(probability=True)\n",
    "parameters = [{'kernel': ['linear'], 'C': [1]}]\n",
    "clfsvc, test_accuracy, test_auc  = do_classify_aa(clfsvc, parameters, dfglioma, colswewant_cont, 'Targets', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
